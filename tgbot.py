import os
import logging
import shutil
import numpy as np
import time
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from ultralytics import YOLO
from PIL import Image
import io
from openai import OpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–ª–∞—Å—Å–æ–≤
CLASS_NAMES = {
    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',
    6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',
    11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',
    16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear',
    22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',
    27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard',
    32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',
    36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',
    40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',
    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',
    51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair',
    57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet',
    62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone',
    68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator',
    73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear',
    78: 'hair drier', 79: 'toothbrush'
}

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO
model = YOLO("yolo11m-seg.pt")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
)

async def get_ai_response(text: str) -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI –º–æ–¥–µ–ª–∏"""
    try:
        response = client.chat.completions.create(
            model="meta-llama/llama-3.1-8b-instruct",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": text}
            ],
            temperature=0.7,
            max_tokens=512
        )
        return response.choices[0].message.content
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é, –∏ —è –æ–±—Ä–∞–±–æ—Ç–∞—é –µ—ë —Å –ø–æ–º–æ—â—å—é YOLO. –ú—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."
    )

async def memory(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /memory"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∏—Å–∫–µ
        total, used, free = shutil.disk_usage("/")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –≥–∏–≥–∞–±–∞–π—Ç—ã
        total_gb = total // (2**30)
        used_gb = used // (2**30)
        free_gb = free // (2**30)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = (
            "üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∏—Å–∫–µ:\n\n"
            f"–í—Å–µ–≥–æ –º–µ—Å—Ç–∞: {total_gb} GB\n"
            f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {used_gb} GB\n"
            f"–°–≤–æ–±–æ–¥–Ω–æ: {free_gb} GB\n"
            f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {used * 100 / total:.1f}%"
        )
        
        await update.message.reply_text(message)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∏—Å–∫–µ: {e}")
        await update.message.reply_text(
            "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∏—Å–∫–µ."
        )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç AI
    response = await get_ai_response(update.message.text)
    await update.message.reply_text(response)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ç–æ
        photo = await update.message.photo[-1].get_file()
        photo_bytes = await photo.download_as_bytearray()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image
        image = Image.open(io.BytesIO(photo_bytes))
        
        # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        start_time = time.time()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é YOLO
        results = model.predict(image, save=False, conf=0.25)
        
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –æ–±—ä–µ–∫—Ç–æ–≤
        detected_classes = set()
        for r in results:
            for c in r.boxes.cls:
                class_id = int(c.item())
                if class_id in CLASS_NAMES:
                    detected_classes.add(CLASS_NAMES[class_id])
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        classes_text = ", ".join(detected_classes)
        prompt = f"–ù–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –µ—Å—Ç—å {classes_text}, –∫–∞–∫ —Ç—ã –¥—É–º–∞–µ—à—å —á—Ç–æ —ç—Ç–æ –∑–∞ –º–µ—Å—Ç–æ?"
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç LLM
        description = await get_ai_response(prompt)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        annotated_image = results[0].plot()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_time = time.time() - start_time
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–∞ (BGR -> RGB)
        annotated_image = annotated_image[..., ::-1]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã
        output = io.BytesIO()
        Image.fromarray(annotated_image).save(output, format='JPEG')
        output.seek(0)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
        await update.message.reply_photo(
            photo=output,
            caption=f"{description}\n\n–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f} —Å–µ–∫—É–Ω–¥"
        )
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ: {e}")
        await update.message.reply_text(
            "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏."
        )

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(token).build()

    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("memory", memory))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    application.run_polling()

if __name__ == '__main__':
    main()
